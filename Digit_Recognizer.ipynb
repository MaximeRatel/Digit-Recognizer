{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Digit Recognizer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXHtgDtqoBp1"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Activation\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau \n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from keras.optimizers import RMSprop, SGD\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM0N2FnDhD0b",
        "outputId": "eabce043-a2ff-4566-fed8-a1c8b564b29d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"mratel\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"\" # key from the json file\n",
        "\n",
        "!kaggle competitions download -c digit-recognizer\n",
        "\n",
        "train = pd.read_csv('train.csv.zip')\n",
        "test = pd.read_csv('test.csv.zip')\n",
        "\n",
        "y_train = train[\"label\"]\n",
        "X_train = train.drop(labels=\"label\", axis=1)\n",
        "\n",
        "#sns.countplot(y_train)\n",
        "#X_train.isnull().any().describe()\n",
        "#test.isnull().any().describe()\n",
        "\n",
        "# Normalisation\n",
        "X_train = X_train / 255\n",
        "test = test / 255\n",
        "\n",
        "#Reshape pour convolution\n",
        "X_train1 = X_train.values.reshape(-1,28,28,1)\n",
        "test1 = test.values.reshape(-1,28,28,1)\n",
        "\n",
        "#Encodage label\n",
        "y_train = to_categorical(y_train, num_classes = 10)\n",
        "\n",
        "#Split apprentissage/validation\n",
        "X_app, X_val, y_app, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=2)\n",
        "\n",
        "#Split apprentissage/validation convolution\n",
        "X_app1, X_val1, y_app, y_val = train_test_split(X_train1, y_train, test_size=0.1, random_state=2, stratify=y_train)\n",
        "\n",
        "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
        "\n",
        "#g = plt.imshow(X_train1[3][:,:,0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "sample_submission.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfH_BY2XFwI7"
      },
      "source": [
        "# NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrYJ2_JaFvmA"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(800, input_shape=(784,)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dense(units=10))\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "optimizer1 = SGD(lr=0.001, momentum=0.0, nesterov=False)\n",
        "optimizer2 = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
        "\n",
        "model.compile(optimizer = optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_app, y_app, validation_data = (X_val, y_val), epochs=10, batch_size=86)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6gPn5TO2vkP"
      },
      "source": [
        "pred = model.predict(test)\n",
        "\n",
        "pred = np.argmax(pred, axis = 1)\n",
        "\n",
        "pred = pd.Series(pred, name=\"Label\")\n",
        "\n",
        "submission = pd.concat([pd.Series(range(1,28001), name = \"ImageId\"),pred],axis = 1)\n",
        "\n",
        "submission.to_csv(\"submission_mnist.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4ODrqEHMXBq"
      },
      "source": [
        "model.predict(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JC-32AcEq45O"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x7MamaUq24V"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=False,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "datagen.fit(X_app1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAUcJgfWnJ8a"
      },
      "source": [
        "# Small CNN "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmiwoq97nJl9"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=64,kernel_size=(3,3), input_shape=(28,28,1), activation='relu'))\n",
        "model.add(Conv2D(filters=32,kernel_size=(3,3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=10))\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "model.compile(optimizer = optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_app1, y_app, validation_data = (X_val1, y_val), epochs=10, batch_size=32, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JoUmhddv9fq"
      },
      "source": [
        "pred = model.predict(test1)\n",
        "\n",
        "pred = np.argmax(pred, axis = 1)\n",
        "\n",
        "pred = pd.Series(pred, name=\"Label\")\n",
        "\n",
        "submission = pd.concat([pd.Series(range(1,28001), name = \"ImageId\"),pred],axis = 1)\n",
        "\n",
        "submission.to_csv(\"submission_mnist.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7bjDPJxAfsU"
      },
      "source": [
        "# Medium CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx0Upd_nvu1p"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1)))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation = \"relu\"))\n",
        "model.add(Dense(10, activation = \"softmax\"))\n",
        "\n",
        "model.compile(optimizer = optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "es = [EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2), ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n",
        "\n",
        "model.fit(X_app1, y_app, validation_data = (X_val1, y_val), epochs=10, batch_size=32, verbose=1, callbacks=es)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scnzUIjTAG2B"
      },
      "source": [
        "#On charge le meilleur modèle enregistré\n",
        "model = load_model('best_model.h5')\n",
        "\n",
        "pred = model.predict(test1)\n",
        "\n",
        "pred = np.argmax(pred, axis = 1)\n",
        "\n",
        "pred = pd.Series(pred, name=\"Label\")\n",
        "\n",
        "submission = pd.concat([pd.Series(range(1,28001), name = \"ImageId\"),pred],axis = 1)\n",
        "\n",
        "submission.to_csv(\"submission_mnist.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0W2_jN2o6dc"
      },
      "source": [
        "# Large CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shY9aaxuFvay",
        "outputId": "5849eb2a-d63e-47ac-93cd-fc8e9f15666c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        }
      },
      "source": [
        "batch_size=32\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters = 30, kernel_size = (5,5), activation ='relu', input_shape = (28,28,1)))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(filters = 15, kernel_size = (3,3), activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation = \"relu\"))\n",
        "model.add(Dense(50, activation = \"relu\"))\n",
        "model.add(Dense(10, activation = \"softmax\"))\n",
        "\n",
        "model.compile(optimizer = 'adam', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "es = [EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2), ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n",
        "\n",
        "model.fit_generator(datagen.flow(X_app1, y_app, batch_size=batch_size), validation_data = (X_val1, y_val), epochs=30, steps_per_epoch=X_app1.shape[0] / batch_size, verbose=1, callbacks=es)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1182/1181 [==============================] - 36s 31ms/step - loss: 0.4432 - acc: 0.8547 - val_loss: 0.0837 - val_acc: 0.9755\n",
            "Epoch 2/30\n",
            "1182/1181 [==============================] - 36s 31ms/step - loss: 0.1680 - acc: 0.9480 - val_loss: 0.0677 - val_acc: 0.9802\n",
            "Epoch 3/30\n",
            "1182/1181 [==============================] - 36s 31ms/step - loss: 0.1290 - acc: 0.9589 - val_loss: 0.0569 - val_acc: 0.9831\n",
            "Epoch 4/30\n",
            "1182/1181 [==============================] - 36s 30ms/step - loss: 0.1110 - acc: 0.9656 - val_loss: 0.0511 - val_acc: 0.9850\n",
            "Epoch 5/30\n",
            "1182/1181 [==============================] - 35s 30ms/step - loss: 0.1003 - acc: 0.9689 - val_loss: 0.0451 - val_acc: 0.9864\n",
            "Epoch 6/30\n",
            "1182/1181 [==============================] - 35s 30ms/step - loss: 0.0888 - acc: 0.9718 - val_loss: 0.0387 - val_acc: 0.9881\n",
            "Epoch 7/30\n",
            "1182/1181 [==============================] - 36s 30ms/step - loss: 0.0833 - acc: 0.9749 - val_loss: 0.0305 - val_acc: 0.9902\n",
            "Epoch 8/30\n",
            "1182/1181 [==============================] - 35s 30ms/step - loss: 0.0799 - acc: 0.9744 - val_loss: 0.0419 - val_acc: 0.9879\n",
            "Epoch 9/30\n",
            "1182/1181 [==============================] - 36s 30ms/step - loss: 0.0802 - acc: 0.9757 - val_loss: 0.0384 - val_acc: 0.9895\n",
            "Epoch 00009: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f47a9c03128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppwJP5mfFvSA"
      },
      "source": [
        "#On charge le meilleur modèle enregistré\n",
        "model = load_model('best_model.h5')\n",
        "\n",
        "pred = model.predict(test1)\n",
        "\n",
        "pred = np.argmax(pred, axis = 1)\n",
        "\n",
        "pred = pd.Series(pred, name=\"Label\")\n",
        "\n",
        "submission = pd.concat([pd.Series(range(1,28001), name = \"ImageId\"),pred],axis = 1)\n",
        "\n",
        "submission.to_csv(\"largeCNN.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1tHj6tIr9by"
      },
      "source": [
        "# CNN ghouzam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2XpdT0SFvKB",
        "outputId": "e8b4973d-041e-486e-fcc1-40353b9ec269",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Set the CNN model \n",
        "# my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu', input_shape = (28,28,1)))\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation = \"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation = \"softmax\"))\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Set a learning rate annealer\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
        "                                            patience=3, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00001)\n",
        "\n",
        "batch_size = 86\n",
        "\n",
        "es = [EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=300), ModelCheckpoint(filepath='best_model.h5', monitor='val_acc', save_best_only=True), learning_rate_reduction]\n",
        "\n",
        "model.fit_generator(datagen.flow(X_app1, y_app, batch_size=batch_size),\n",
        "                              epochs = 30, validation_data = (X_val1,y_val),\n",
        "                              verbose = 1, steps_per_epoch=X_train.shape[0] / batch_size\n",
        "                              , callbacks=es)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "489/488 [==============================] - 297s 608ms/step - loss: 0.4132 - acc: 0.8700 - val_loss: 0.0579 - val_acc: 0.9795\n",
            "Epoch 2/30\n",
            "489/488 [==============================] - 293s 599ms/step - loss: 0.1524 - acc: 0.9559 - val_loss: 0.0495 - val_acc: 0.9855\n",
            "Epoch 3/30\n",
            "489/488 [==============================] - 293s 598ms/step - loss: 0.1320 - acc: 0.9641 - val_loss: 0.0443 - val_acc: 0.9886\n",
            "Epoch 4/30\n",
            "489/488 [==============================] - 293s 600ms/step - loss: 0.1259 - acc: 0.9675 - val_loss: 0.0581 - val_acc: 0.9848\n",
            "Epoch 5/30\n",
            "489/488 [==============================] - 295s 603ms/step - loss: 0.1252 - acc: 0.9686 - val_loss: 0.0628 - val_acc: 0.9860\n",
            "Epoch 6/30\n",
            "489/488 [==============================] - 293s 600ms/step - loss: 0.1309 - acc: 0.9702 - val_loss: 0.0426 - val_acc: 0.9864\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 7/30\n",
            "489/488 [==============================] - 294s 600ms/step - loss: 0.0828 - acc: 0.9782 - val_loss: 0.0309 - val_acc: 0.9912\n",
            "Epoch 8/30\n",
            "489/488 [==============================] - 294s 600ms/step - loss: 0.0825 - acc: 0.9784 - val_loss: 0.0261 - val_acc: 0.9912\n",
            "Epoch 9/30\n",
            "489/488 [==============================] - 295s 603ms/step - loss: 0.0820 - acc: 0.9789 - val_loss: 0.0266 - val_acc: 0.9929\n",
            "Epoch 10/30\n",
            "489/488 [==============================] - 295s 603ms/step - loss: 0.0848 - acc: 0.9789 - val_loss: 0.0390 - val_acc: 0.9895\n",
            "Epoch 11/30\n",
            "489/488 [==============================] - 294s 602ms/step - loss: 0.0836 - acc: 0.9794 - val_loss: 0.0299 - val_acc: 0.9919\n",
            "Epoch 12/30\n",
            "489/488 [==============================] - 296s 605ms/step - loss: 0.0864 - acc: 0.9782 - val_loss: 0.0363 - val_acc: 0.9912\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 13/30\n",
            "489/488 [==============================] - 295s 603ms/step - loss: 0.0662 - acc: 0.9828 - val_loss: 0.0312 - val_acc: 0.9900\n",
            "Epoch 14/30\n",
            "489/488 [==============================] - 294s 602ms/step - loss: 0.0686 - acc: 0.9831 - val_loss: 0.0266 - val_acc: 0.9924\n",
            "Epoch 15/30\n",
            "489/488 [==============================] - 294s 601ms/step - loss: 0.0657 - acc: 0.9824 - val_loss: 0.0245 - val_acc: 0.9936\n",
            "Epoch 16/30\n",
            "489/488 [==============================] - 294s 601ms/step - loss: 0.0694 - acc: 0.9829 - val_loss: 0.0278 - val_acc: 0.9914\n",
            "Epoch 17/30\n",
            "489/488 [==============================] - 296s 606ms/step - loss: 0.0673 - acc: 0.9821 - val_loss: 0.0334 - val_acc: 0.9926\n",
            "Epoch 18/30\n",
            "489/488 [==============================] - 296s 606ms/step - loss: 0.0707 - acc: 0.9817 - val_loss: 0.0297 - val_acc: 0.9917\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 19/30\n",
            "489/488 [==============================] - 297s 607ms/step - loss: 0.0581 - acc: 0.9849 - val_loss: 0.0226 - val_acc: 0.9926\n",
            "Epoch 20/30\n",
            "489/488 [==============================] - 296s 605ms/step - loss: 0.0583 - acc: 0.9849 - val_loss: 0.0247 - val_acc: 0.9926\n",
            "Epoch 21/30\n",
            "489/488 [==============================] - 293s 599ms/step - loss: 0.0532 - acc: 0.9853 - val_loss: 0.0285 - val_acc: 0.9910\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "Epoch 22/30\n",
            "489/488 [==============================] - 296s 605ms/step - loss: 0.0512 - acc: 0.9863 - val_loss: 0.0219 - val_acc: 0.9921\n",
            "Epoch 23/30\n",
            "489/488 [==============================] - 295s 604ms/step - loss: 0.0534 - acc: 0.9857 - val_loss: 0.0224 - val_acc: 0.9926\n",
            "Epoch 24/30\n",
            "489/488 [==============================] - 293s 599ms/step - loss: 0.0480 - acc: 0.9868 - val_loss: 0.0221 - val_acc: 0.9926\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "Epoch 25/30\n",
            "489/488 [==============================] - 293s 599ms/step - loss: 0.0515 - acc: 0.9871 - val_loss: 0.0206 - val_acc: 0.9926\n",
            "Epoch 26/30\n",
            "489/488 [==============================] - 293s 599ms/step - loss: 0.0467 - acc: 0.9872 - val_loss: 0.0207 - val_acc: 0.9924\n",
            "Epoch 27/30\n",
            "489/488 [==============================] - 293s 599ms/step - loss: 0.0476 - acc: 0.9869 - val_loss: 0.0221 - val_acc: 0.9929\n",
            "\n",
            "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "Epoch 28/30\n",
            "489/488 [==============================] - 293s 600ms/step - loss: 0.0490 - acc: 0.9871 - val_loss: 0.0212 - val_acc: 0.9921\n",
            "Epoch 29/30\n",
            "489/488 [==============================] - 302s 618ms/step - loss: 0.0459 - acc: 0.9873 - val_loss: 0.0208 - val_acc: 0.9929\n",
            "Epoch 30/30\n",
            "489/488 [==============================] - 303s 619ms/step - loss: 0.0438 - acc: 0.9874 - val_loss: 0.0202 - val_acc: 0.9924\n",
            "\n",
            "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1e-05.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f47a8d4b550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIUhsuH9sF-q"
      },
      "source": [
        "#On charge le meilleur modèle enregistré\n",
        "model = load_model('best_model.h5')\n",
        "\n",
        "pred = model.predict(test1)\n",
        "\n",
        "pred = np.argmax(pred, axis = 1)\n",
        "\n",
        "pred = pd.Series(pred, name=\"Label\")\n",
        "\n",
        "submission = pd.concat([pd.Series(range(1,28001), name = \"ImageId\"),pred],axis = 1)\n",
        "\n",
        "submission.to_csv(\"largeCNN.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}